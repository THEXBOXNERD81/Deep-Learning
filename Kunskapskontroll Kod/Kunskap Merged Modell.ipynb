{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Laddar in modeller som ska kombineras\n",
    "from keras.models import load_model\n",
    "\n",
    "face = load_model(r'C:\\Users\\leona\\Desktop\\Data Science\\face.tf')\n",
    "speech = load_model(r'C:\\Users\\leona\\Desktop\\Data Science\\speechgg2lt.tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# För att undvika namnkonflikter när modellerna kombineras, lägg till ett suffix på alla lager i talmodellen.\n",
    "# Detta är för att hantera en potentiell bugg i Keras.\n",
    "for i, layer in enumerate(speech.layers):\n",
    "    layer._name = layer._name + str(\"_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkar att namnen har ändrats\n",
    "for i, layer in enumerate(speech.layers):\n",
    "    print(layer, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laddar in bilddata som användes från modellen innan. \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Importing Deep Learning Libraries\n",
    "\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "picture_size = 48\n",
    "folder_path = 'D:/DataSets/images/images/Images Merge'\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "datagen_train = ImageDataGenerator()\n",
    "datagen_val = ImageDataGenerator()\n",
    "\n",
    "### https://stackoverflow.com/questions/42284873/assign-imagedatagenerator-result-to-numpy-array\n",
    "### https://www.bing.com/search?q=keras+ImageDataGenerator+to+np.array&qs=n&form=QBRE&sp=-1&lq=0&pq=keras+imagedatagenerator+to+np.array&sc=11-36&sk=&cvid=64B6BA2699D84DCDA7653B0DE6C00DE6&ghsh=0&ghacc=0&ghpl=\n",
    "\n",
    "train_set = datagen_train.flow_from_directory(folder_path+'train',\n",
    "                                              target_size = (picture_size, picture_size),\n",
    "                                              color_mode ='grayscale',\n",
    "                                              batch_size = batch_size,\n",
    "                                              class_mode = 'categorical',\n",
    "                                              shuffle = True)\n",
    "\n",
    "test_set = datagen_train.flow_from_directory(folder_path+'validation',\n",
    "                                              target_size = (picture_size, picture_size),\n",
    "                                              color_mode = 'grayscale',\n",
    "                                              batch_size = batch_size,\n",
    "                                              class_mode = 'categorical',\n",
    "                                              shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konvertera data till numpy arrays för att säkerställa att all data som matas in i modellen har samma datatype\n",
    "# Datan kommer att vara numpy arrays.\n",
    "\n",
    "x_train=np.concatenate([train_set.next()[0] for i in range(train_set.__len__())])\n",
    "y_train=np.concatenate([train_set.next()[1] for i in range(train_set.__len__())])\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konvertera data till numpy arrays för att säkerställa att all data som matas in i modellen har samma datatype\n",
    "# Datan kommer att vara numpy arrays.\n",
    "\n",
    "x_test=np.concatenate([test_set.next()[0] for i in range(test_set.__len__())])\n",
    "y_test=np.concatenate([test_set.next()[1] for i in range(test_set.__len__())])\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(train_set)\n",
    "type(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []\n",
    "labels = []\n",
    "\n",
    "def sorting_sounds(emotion):\n",
    "    # Laddar datasetet och extraherar filvägar och etiketter från filnamnen\n",
    "#labels = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "\n",
    "    x = 0\n",
    "    # Traversera alla filer i datasetets katalogstruktur\n",
    "    for dirname, _, filenames in os.walk(r'D:\\DataSets\\AudioWAV'):\n",
    "        for filename in filenames:\n",
    "            # Lagra fullständig filväg\n",
    "\n",
    "            label = filename.split('_')[-2]\n",
    "            if label == emotion and not label == 'DIS':\n",
    "                paths.append(os.path.join(dirname, filename))\n",
    "                labels.append(label.lower())\n",
    "\n",
    "            elif label == 'DIS' and emotion == 'DIS' and x < 436:\n",
    "                paths.append(os.path.join(dirname, filename))\n",
    "                labels.append(label.lower())\n",
    "                x += 1\n",
    "            # Extrahera etikett från filnamnet\n",
    "            \n",
    "\n",
    "                \n",
    "            #label = label.split('.')[0]\n",
    "            #print(label)\n",
    "            \n",
    "        print('Dataset is loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "from IPython.display import Audio\n",
    "\n",
    "sorting_sounds('ANG')\n",
    "sorting_sounds('DIS')\n",
    "sorting_sounds('FEA')\n",
    "sorting_sounds('HAP')\n",
    "sorting_sounds('NEU')\n",
    "sorting_sounds('SAD')\n",
    "\n",
    "## create a dataframe\n",
    "df = pd.DataFrame()\n",
    "df['speech'] = paths\n",
    "df['labels'] = labels\n",
    "\n",
    "df['labels']= df['labels'].replace({'ps': 'surprise'})\n",
    "\n",
    "def extract_mfcc(filename):\n",
    "  y, sr = librosa.load(filename, duration=3, offset=0.5)\n",
    "  mfcc = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T, axis=0)\n",
    "  return mfcc\n",
    "\n",
    "X_mfcc = df['speech'].apply(lambda x: extract_mfcc(x))\n",
    "\n",
    "X = [x for x in X_mfcc]\n",
    "X = np.array(X)\n",
    "X = np.expand_dims(X, -1)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "y = enc.fit_transform(df[['labels']])\n",
    "y = y.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laddar in ljuddata som ska användas för att träna den nya modellen\n",
    "\n",
    "#Audio data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "from IPython.display import Audio\n",
    "\n",
    "paths = []\n",
    "labels = []\n",
    "for dirname, _, filenames in os.walk('D:\\DataSets\\TESS Toronto emotional speech set data 2'):\n",
    "  for filename in filenames:\n",
    "    paths.append(os.path.join(dirname, filename))\n",
    "    label = filename.split('_')[-1]\n",
    "    label = label.split('.')[0]\n",
    "    labels.append(label.lower())\n",
    "print('Dataset is loaded')\n",
    "\n",
    "## create a dataframe\n",
    "df = pd.DataFrame()\n",
    "df['speech'] = paths\n",
    "df['labels'] = labels\n",
    "\n",
    "df['labels']= df['labels'].replace({'ps': 'surprise'})\n",
    "\n",
    "def extract_mfcc(filename):\n",
    "  y, sr = librosa.load(filename, duration=3, offset=0.5)\n",
    "  mfcc = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T, axis=0)\n",
    "  return mfcc\n",
    "\n",
    "X_mfcc = df['speech'].apply(lambda x: extract_mfcc(x))\n",
    "\n",
    "X = [x for x in X_mfcc]\n",
    "X = np.array(X)\n",
    "X = np.expand_dims(X, -1)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "y = enc.fit_transform(df[['labels']])\n",
    "y = y.toarray()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detta görs för att kombinera de två sparade modellerna för ansikts- och taligenkänning\n",
    "\n",
    "from keras.layers import Concatenate, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras import metrics\n",
    "\n",
    "# Skapar en ny modell som kombinerar utgångarna från ansikts- och talmodellerna\n",
    "merged_output = Concatenate()([face.output, speech.output])\n",
    "\n",
    "# Första nya fullt anslutna lagret för att kombinera funktioner från båda modellerna\n",
    "new_layer = Dense(256, activation='relu')(merged_output)\n",
    "new_layer = Dropout(0.2)(new_layer)  # Förhindrar överanpassning\n",
    "\n",
    "# Andra nya fullt anslutna lagret för ytterligare funktionkombination\n",
    "new_layer = Dense(128, activation='relu')(new_layer)\n",
    "\n",
    "# Utgångslager med softmax-aktivering för klassificering i 6 kategorier\n",
    "new_layer = Dense(6, activation='softmax')(new_layer)\n",
    "\n",
    "# Skapar den nya kombinerade modellen med båda ingångarna och det nya utgångslagret\n",
    "new_model = Model([face.input, speech.input], new_layer)\n",
    "\n",
    "# Kompilering av den nya modellen med Adam-optimizer och kategorisk korsentropi som förlustfunktion\n",
    "opt = Adam(learning_rate=0.0001)\n",
    "new_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=[metrics.categorical_accuracy])\n",
    "\n",
    "# Sammanfattar arkitekturen för den nya kombinerade modellen\n",
    "new_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparar modellen så att den kan användas senare, samt tillämpar olika regulariseringsmetoder för att förbättra modellen\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Checkpoint för att spara den bästa modellen baserat på valideringsnoggrannhet\n",
    "checkpoint = ModelCheckpoint(\"./fn.tf\", monitor=\"val_categorical_accuracy\", verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "# Early stopping för att avbryta träningen när noggrannheten slutar förbättras för att undvika överträning\n",
    "early_stopping = EarlyStopping(monitor='categorical_accuracy',\n",
    "                               min_delta=0,\n",
    "                               patience=3,\n",
    "                               verbose=1,\n",
    "                               restore_best_weights=True)\n",
    "\n",
    "# Reduce learning rate on plateau för att minska inlärningshastigheten när noggrannheten slutar förbättras\n",
    "reduce_learningrate = ReduceLROnPlateau(monitor='categorical_accuracy',\n",
    "                                        factor=0.2,\n",
    "                                        patience=3,\n",
    "                                        verbose=1,\n",
    "                                        min_delta=0.0001)\n",
    "\n",
    "callbacks_list = [early_stopping, checkpoint, reduce_learningrate]\n",
    "\n",
    "epochs = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tränar modellen med träningsdata och validerar med valideringsdata\n",
    "# Använder callbacks för att spara bästa modell, avbryta vid överträning och justera inlärningshastigheten\n",
    "\n",
    "history = new_model.fit(          \n",
    "    x=[x_train, X],\n",
    "    y=[y_train, y], \n",
    "    steps_per_epoch= 35, ###train_set.n//train_set.batch_size,\n",
    "    epochs=epochs, \n",
    "    validation_split=0.20,\n",
    "    validation_steps= 9, ###test_set.n//test_set.batch_size,\n",
    "    callbacks=callbacks_list\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualiserar tränings- och valideringsförlust samt noggrannhet för att bedöma modellens prestanda och avgöra om ytterligare träning behövs\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Plot för tränings- och valideringsförlust\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Optimizer : Adam', fontsize=10)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "# Plot för tränings- och valideringsnoggrannhet\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.ylabel('Accuracy', fontsize=16)\n",
    "plt.plot(history.history['categorical_accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_categorical_accuracy'], label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Säkerställer att modellen fungerar med rätt dimensioner\n",
    "xf = x_test[150]\n",
    "xs = X[150]\n",
    "\n",
    "xf = np.expand_dims(xf, axis=0)\n",
    "xs = np.expand_dims(xs, axis=0)\n",
    "\n",
    "new_model.predict([xf, xs])[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
