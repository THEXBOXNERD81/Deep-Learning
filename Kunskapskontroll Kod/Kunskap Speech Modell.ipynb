{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laddar datasetet och extraherar filvägar och etiketter från filnamnen\n",
    "#labels = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "paths = []\n",
    "labels = []\n",
    "\n",
    "# Traversera alla filer i datasetets katalogstruktur\n",
    "for dirname, _, filenames in os.walk(r'D:\\DataSets\\AudioWAV'):\n",
    "  for filename in filenames:\n",
    "    # Lagra fullständig filväg\n",
    "    paths.append(os.path.join(dirname, filename))\n",
    "    # Extrahera etikett från filnamnet\n",
    "    label = filename.split('_')[-2]\n",
    "    \n",
    "    match label:\n",
    "        case 'ANG':\n",
    "          label = 'angry' \n",
    "        case 'DIS':\n",
    "          label = 'disgust'\n",
    "        case 'FEA':\n",
    "          label = 'fear'\n",
    "        case 'HAP':\n",
    "          label = 'happy'\n",
    "        case 'NEU':\n",
    "          label = 'neutral'\n",
    "        case 'SAD':\n",
    "          label = 'sad'\n",
    "\n",
    "\n",
    "    print(label)\n",
    "    #label = label.split('.')[0]\n",
    "    #print(label)\n",
    "    labels.append(label.lower())\n",
    "print('Dataset is loaded')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Skapar en DataFrame för att organisera filvägar och etiketter för vidare analys och modellträning\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['speech'] = paths\n",
    "df['labels'] = labels\n",
    "\n",
    "# Visar de första raderna i DataFrame för att bekräfta att data har laddats korrekt\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "sns.countplot(df['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiserar ljudvågsformen för en given ljuddata med emotion som titel\n",
    "def waveplot(data, sr, emotion):\n",
    "  plt.figure(figsize=(10,4))\n",
    "  plt.title(emotion, size=20)\n",
    "  librosa.display.waveshow(data, sr=sr)\n",
    "  plt.show()\n",
    "\n",
    "# Skapar ett spektrogram för en given ljuddata med emotion som titel\n",
    "def spectogram(data, sr, emotion):\n",
    "  x = librosa.stft(data) \n",
    "  xdb = librosa.amplitude_to_db(abs(x)) \n",
    "  plt.figure(figsize=(10,4))\n",
    "  plt.title(emotion, size=20)\n",
    "  librosa.display.specshow(xdb, sr=sr, x_axis='time', y_axis='hz')\n",
    "  plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kollar så att datan ser bra ut och se eventuella skillnader mellan känslor\n",
    "emotion = 'fear'\n",
    "path = np.array(df['speech'][df['labels'] == emotion])[0]\n",
    "data, sampling_rate = librosa.load(path)\n",
    "waveplot(data, sampling_rate, emotion)\n",
    "spectogram(data, sampling_rate, emotion)\n",
    "Audio(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion = 'fear'\n",
    "path = np.array(df['speech'][df['labels'] == emotion])[0]\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kollar så att datan ser bra ut och se eventuella skillnader mellan känslor\n",
    "emotion = 'angry'\n",
    "path = np.array(df['speech'][df['labels'] == emotion])[0]\n",
    "data, sampling_rate = librosa.load(path)\n",
    "waveplot(data, sampling_rate, emotion)\n",
    "spectogram(data, sampling_rate, emotion)\n",
    "Audio(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kollar så att datan ser bra ut och se eventuella skillnader mellan känslor\n",
    "emotion = 'disgust'\n",
    "path = np.array(df['speech'][df['labels'] == emotion])[0]\n",
    "data, sampling_rate = librosa.load(path)\n",
    "waveplot(data, sampling_rate, emotion)\n",
    "spectogram(data, sampling_rate, emotion)\n",
    "Audio(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kollar så att datan ser bra ut och se eventuella skillnader mellan känslor\n",
    "emotion = 'neutral'\n",
    "path = np.array(df['speech'][df['labels'] == emotion])[0]\n",
    "data, sampling_rate = librosa.load(path)\n",
    "waveplot(data, sampling_rate, emotion)\n",
    "spectogram(data, sampling_rate, emotion)\n",
    "Audio(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kollar så att datan ser bra ut och se eventuella skillnader mellan känslor\n",
    "emotion = 'sad'\n",
    "path = np.array(df['speech'][df['labels'] == emotion])[0]\n",
    "data, sampling_rate = librosa.load(path)\n",
    "waveplot(data, sampling_rate, emotion)\n",
    "spectogram(data, sampling_rate, emotion)\n",
    "Audio(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kollar så att datan ser bra ut och se eventuella skillnader mellan känslor\n",
    "emotion = 'happy'\n",
    "path = np.array(df['speech'][df['labels'] == emotion])[0]\n",
    "data, sampling_rate = librosa.load(path)\n",
    "waveplot(data, sampling_rate, emotion)\n",
    "spectogram(data, sampling_rate, emotion)\n",
    "Audio(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konverterar ljudfilen till MFCC (Mel-Frequency Cepstral Coefficients) eftersom det är mer lämpligt för \n",
    "# att skapa en känsloigenkänningsmodell\n",
    "\n",
    "def extract_mfcc(filename):\n",
    "  y, sr = librosa.load(filename, duration=3, offset=0.5)\n",
    "  mfcc = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T, axis=0)\n",
    "  return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkar funktionen\n",
    "extract_mfcc(df['speech'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraherar MFCC (Mel-Frequency Cepstral Coefficients) för varje ljudfil\n",
    "X_mfcc = df['speech'].apply(lambda x: extract_mfcc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ändrar datatypen till numpy array\n",
    "X = [x for x in X_mfcc]\n",
    "X = np.array(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lägger till en extra dimension till X för att uppfylla modellens inputkrav\n",
    "X = np.expand_dims(X, -1)\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konverterar alla labels till one-hot kodning för att möjliggöra klassificering av modellen\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "y = enc.fit_transform(df[['labels']])\n",
    "y = y.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ckeckar dimensioner\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, Bidirectional, BatchNormalization, Conv1D, MaxPooling1D, Flatten\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Skapar en sekventiell modell för att klassificera ljuddata\n",
    "model = Sequential([\n",
    "    # Första konvolutionslagret för att extrahera funktioner från tidsseriedata\n",
    "    Conv1D(32, kernel_size=(3), activation='relu', input_shape=(40, 1)),  \n",
    "    MaxPooling1D(pool_size=(2)),  # Minskar dimensionerna och behåller viktiga funktioner\n",
    "    Dropout(0.3),  # Förhindrar överanpassning\n",
    "\n",
    "    # Andra konvolutionslagret för att extrahera mer komplexa funktioner\n",
    "    Conv1D(64, kernel_size=(3), activation='relu'),\n",
    "    MaxPooling1D(pool_size=(2)),  # Minskar dimensionerna ytterligare\n",
    "    Dropout(0.3),  # Förhindrar överanpassning\n",
    "\n",
    "    Flatten(),  # Omvandlar data till en dimension för fullt anslutna lager\n",
    "\n",
    "    # Första fullt anslutna lagret för att kombinera extraherade funktioner\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),  # Förhindrar överanpassning\n",
    "    BatchNormalization(),  # Normaliserar data för snabbare konvergens och stabilitet\n",
    "\n",
    "    # Andra fullt anslutna lagret för ytterligare funktionkombination\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),  # Förhindrar överanpassning\n",
    "    BatchNormalization(),  # Normaliserar data\n",
    "\n",
    "    # Tredje fullt anslutna lagret för ytterligare funktionkombination\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.3),  # Förhindrar överanpassning\n",
    "\n",
    "    # Utgångslager med softmax-aktivering för klassificering i 6 kategorier\n",
    "    Dense(6, activation='softmax')\n",
    "])\n",
    "\n",
    "# Kompilering av modellen med kategorisk korsentropi som förlustfunktion och Adam som optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Sammanfattar modellens arkitektur\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparar modellen så att den kan användas senare, samt tillämpar olika regulariseringsmetoder för att förbättra modellen\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Checkpoint för att spara den bästa modellen baserat på valideringsnoggrannhet\n",
    "checkpoint = ModelCheckpoint(\"./speechgg2lt.tf\", monitor=\"val_accuracy\", verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "# Early stopping för att avbryta träningen när noggrannheten slutar förbättras för att undvika överträning\n",
    "early_stopping = EarlyStopping(monitor='accuracy',\n",
    "                               min_delta=0,\n",
    "                               patience=3,\n",
    "                               verbose=1,\n",
    "                               restore_best_weights=True)\n",
    "\n",
    "# Reduce learning rate on plateau för att minska inlärningshastigheten när noggrannheten slutar förbättras\n",
    "reduce_learningrate = ReduceLROnPlateau(monitor='accuracy',\n",
    "                                        factor=0.2,\n",
    "                                        patience=3,\n",
    "                                        verbose=1,\n",
    "                                        min_delta=0.0001)\n",
    "\n",
    "callbacks_list = [early_stopping, checkpoint, reduce_learningrate]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tränar modellen med träningsdata och validerar med uppdelad träningsdata\n",
    "# Använder callbacks för att spara bästa modell, avbryta vid överträning och justera inlärningshastigheten\n",
    "\n",
    "history = model.fit(\n",
    "    X, \n",
    "    y, \n",
    "    validation_split=0.2, \n",
    "    epochs=100, \n",
    "    batch_size=64, \n",
    "    shuffle=True, \n",
    "    callbacks=callbacks_list\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualiserar tränings- och valideringsförlust samt noggrannhet för att bedöma modellens prestanda och avgöra om ytterligare träning behövs\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Plot för tränings- och valideringsförlust\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Optimizer : Adam', fontsize=10)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "# Plot för tränings- och valideringsnoggrannhet\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.ylabel('Accuracy', fontsize=16)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
