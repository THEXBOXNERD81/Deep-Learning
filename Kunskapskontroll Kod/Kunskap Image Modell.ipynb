{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Important Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Importerar nödvändiga Libraries\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Importing Deep Learning Libraries ipykernel\n",
    "\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Input, Dropout, GlobalAveragePooling2D, Flatten, Conv2D, BatchNormalization, Activation, MaxPooling2D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folder_path = 'D:/DataSets/images/images/'\n",
    "picture_size = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualiserar exempelbilder för att kontrollera att bilderna laddas in korrekt och ser ut som förväntat\n",
    "\n",
    "\n",
    "expression = 'disgust'\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "for i in range(1, 10, 1):\n",
    "  plt.subplot(3, 3, i)\n",
    "  img = load_img(folder_path+'train/'+expression+'/'+\n",
    "                 os.listdir(folder_path + 'train/' + expression)[i], target_size=(picture_size, picture_size))\n",
    "  plt.imshow(img)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Förbereder tränings- och valideringsdata för att användas i modellen\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "datagen_train = ImageDataGenerator()\n",
    "datagen_val = ImageDataGenerator()\n",
    "\n",
    "train_set = datagen_train.flow_from_directory(folder_path+'train',\n",
    "                                              target_size = (picture_size, picture_size),\n",
    "                                              color_mode ='grayscale',\n",
    "                                              batch_size = batch_size,\n",
    "                                              class_mode = 'categorical',\n",
    "                                              shuffle = True)\n",
    "\n",
    "test_set = datagen_val.flow_from_directory(folder_path+'validation',\n",
    "                                              target_size = (picture_size, picture_size),\n",
    "                                              color_mode = 'grayscale',\n",
    "                                              batch_size = batch_size,\n",
    "                                              class_mode = 'categorical',\n",
    "                                              shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skapar modellen med olika lager för att extrahera funktioner och klassificera bilder i 7 kategorier\n",
    "\n",
    "no_of_classes = 6\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Första konvolutionslagret för att extrahera lågnivåfunktioner\n",
    "model.add(Conv2D(64, (3,3), padding = 'same', input_shape = (48, 48, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Andra konvolutionslagret för att extrahera mer komplexa funktioner\n",
    "model.add(Conv2D(128, (5,5), padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Tredje konvolutionslagret för att extrahera ännu mer komplexa funktioner\n",
    "model.add(Conv2D(512, (3,3), padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Fjärde konvolutionslagret för att ytterligare förfina funktionerna\n",
    "model.add(Conv2D(128, (5,5), padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Flatten lagret för att konvertera 2D-data till 1D-data\n",
    "model.add(Flatten())\n",
    "\n",
    "# Första fullt anslutna lagret för att kombinera extraherade funktioner\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Andra fullt anslutna lagret för att ytterligare kombinera funktioner\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Utgångslager med softmax-aktivering för att klassificera i 6 kategorier\n",
    "model.add(Dense(no_of_classes, activation= 'softmax'))\n",
    "\n",
    "# Kompilering av modellen med Adam-optimizer och kategorisk korsentropi som förlustfunktion\n",
    "opt = Adam(learning_rate = 0.0001)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the model with Training and Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparar modellen så att den kan användas senare, samt tillämpar olika regulariseringsmetoder för att förbättra modellen\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Checkpoint för att spara den bästa modellen baserat på valideringsnoggrannhet\n",
    "checkpoint = ModelCheckpoint(\"./face.tf\", monitor=\"val_accuracy\", verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "# Early stopping för att avbryta träningen när noggrannheten slutar förbättras för att undvika överträning\n",
    "early_stopping = EarlyStopping(monitor='accuracy',\n",
    "                               min_delta=0,\n",
    "                               patience=3,\n",
    "                               verbose=1,\n",
    "                               restore_best_weights=True)\n",
    "\n",
    "# Reduce learning rate on plateau för att minska inlärningshastigheten när noggrannheten slutar förbättras\n",
    "reduce_learningrate = ReduceLROnPlateau(monitor='accuracy',\n",
    "                                        factor=0.2,\n",
    "                                        patience=3,\n",
    "                                        verbose=1,\n",
    "                                        min_delta=0.0001)\n",
    "\n",
    "callbacks_list = [early_stopping, checkpoint, reduce_learningrate]\n",
    "\n",
    "epochs = 48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tränar modellen med träningsdata och validerar med valideringsdata\n",
    "# Använder callbacks för att spara bästa modell, avbryta vid överträning och justera inlärningshastigheten\n",
    "\n",
    "history = model.fit(          \n",
    "    train_set,\n",
    "    steps_per_epoch= train_set.n//train_set.batch_size,\n",
    "    epochs=epochs, \n",
    "    validation_data = test_set,\n",
    "    validation_steps=  test_set.n//test_set.batch_size,\n",
    "    callbacks=callbacks_list\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting Accuracy & Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualiserar tränings- och valideringsförlust samt noggrannhet för att bedöma modellens prestanda och avgöra om ytterligare träning behövs\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Plot för tränings- och valideringsförlust\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Optimizer : Adam', fontsize=10)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "# Plot för tränings- och valideringsnoggrannhet\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.ylabel('Accuracy', fontsize=16)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
